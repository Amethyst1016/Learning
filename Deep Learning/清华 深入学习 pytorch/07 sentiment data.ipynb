{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "60cbc95e",
   "metadata": {},
   "source": [
    "## prepare data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31f91b45",
   "metadata": {},
   "source": [
    "### step1: trokenize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "d42036bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import os\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import re\n",
    "import word2seq\n",
    "import pickle\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F \n",
    "from torch.optim import Adam\n",
    "\n",
    "ws = pickle.load(open('./model/ws.pkl', 'rb'))\n",
    "\n",
    "def tokenize(content):\n",
    "    content = re.sub(\"<.*?>\", \" \", content)\n",
    "    content = re.sub(\"'s\", \" is\", content)\n",
    "    content = re.sub(\"'m\", \" am\", content)\n",
    "    filters = [':','\\t','\\n','\\x97','\\x96','#','$','%','&','\\.']\n",
    "    content = re.sub(\"|\".join(filters), \" \", content)\n",
    "    tokens = [i.strip().lower() for i in content.split()]\n",
    "    return tokens\n",
    "\n",
    "class IMDBDataset(Dataset):\n",
    "    def __init__(self, train=True):\n",
    "        super(IMDBDataset, self).__init__()\n",
    "        self.train_path = './data/aclImdb/train'\n",
    "        self.test_path = './data/aclImdb/test'\n",
    "        data_path = self.train_path if train else self.test_path\n",
    "        temp_data_path = [os.path.join(data_path,'pos'), os.path.join(data_path,'neg')]\n",
    "        self.total_file_path = [] # all comment file path\n",
    "        for path in temp_data_path:\n",
    "            file_name_list = os.listdir(path)\n",
    "            file_path_list = [os.path.join(path, i) for i in file_name_list if i.endswith('.txt')]\n",
    "            self.total_file_path.extend(file_path_list)\n",
    "            \n",
    "    def __getitem__(self, index):\n",
    "        file_path = self.total_file_path[index]\n",
    "        label = 0 if file_path.split('\\\\')[-2] == 'neg' else 1\n",
    "        with open(file_path,'r',encoding='UTF-8') as data:\n",
    "            tokens = tokenize(data.read())\n",
    "        return tokens, label\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.total_file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "40878049",
   "metadata": {},
   "outputs": [],
   "source": [
    "max_len = 20\n",
    "\n",
    "def collate_fn(batch):\n",
    "    content, label = zip(*batch)\n",
    "    content = [ws.transform(i, max_len=max_len) for i in content]\n",
    "    content = torch.LongTensor(content)\n",
    "    label = torch.LongTensor(label)\n",
    "    return content, label\n",
    "\n",
    "def get_dataloader(train=True):\n",
    "    imdb = IMDBDataset(train)\n",
    "    data_loader = DataLoader(imdb, batch_size=128, shuffle=True, collate_fn = collate_fn)\n",
    "    return data_loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "08a0de37",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 tensor([[  259,   328,     3,  ...,     3,    13,  1319],\n",
      "        [  729,   618,   858,  ...,  2037,  3692, 12959],\n",
      "        [14146, 14147,     3,  ...,     0,   798,  8487],\n",
      "        ...,\n",
      "        [13028, 18525,  1195,  ...,  4744,    24,    10],\n",
      "        [   10,   373,  1334,  ...,  1976,   504,   127],\n",
      "        [ 1778,  1373,  1092,  ...,  2363,  4139,    24]]) tensor([1, 1, 1, 0, 0, 1, 0, 0, 1, 1, 0, 1, 1, 0, 0, 1, 0, 1, 0, 1, 0, 0, 0, 1,\n",
      "        1, 1, 1, 0, 1, 1, 1, 0, 1, 1, 1, 0, 0, 1, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 0, 1, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0,\n",
      "        1, 1, 1, 1, 1, 1, 0, 0, 0, 1, 1, 1, 0, 0, 0, 1, 0, 0, 1, 1, 0, 0, 0, 1,\n",
      "        1, 0, 0, 0, 0, 0, 1, 1, 1, 1, 0, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1,\n",
      "        1, 0, 0, 1, 0, 0, 1, 0])\n"
     ]
    }
   ],
   "source": [
    "for idx, (Input, target) in enumerate(get_dataloader()):\n",
    "    print(idx, Input, target)\n",
    "    break"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b02f515",
   "metadata": {},
   "source": [
    "### create model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "4f202962",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Model(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Model, self).__init__()\n",
    "        self.embedding = nn.Embedding(len(ws), 100)\n",
    "        self.fc = nn.Linear(max_len*100, 2)\n",
    "    def forward(self, Input):\n",
    "        x = self.embedding(Input)\n",
    "        x = x.view([-1, max_len*100])\n",
    "        out = self.fc(x)\n",
    "        return F.log_softmax(out, dim=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "33b9d4bf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7546595931053162\n",
      "0.7508937120437622\n",
      "0.7551367878913879\n",
      "0.7034208178520203\n",
      "0.7682862877845764\n",
      "0.7443813681602478\n",
      "0.7299940586090088\n",
      "0.6973925232887268\n",
      "0.6996548175811768\n",
      "0.7131869196891785\n",
      "0.685352623462677\n",
      "0.7099332213401794\n",
      "0.6893857717514038\n",
      "0.7115482687950134\n",
      "0.7044959664344788\n",
      "0.6678099036216736\n",
      "0.6535273790359497\n",
      "0.6993693113327026\n",
      "0.713651716709137\n",
      "0.6516751050949097\n"
     ]
    }
   ],
   "source": [
    "model = Model()\n",
    "optimizer = Adam(model.parameters(), 0.001)\n",
    "def train(epoch):\n",
    "    for idx, (Input, target) in enumerate(get_dataloader(train=True)):\n",
    "        predict = model(Input)\n",
    "        optimizer.zero_grad()\n",
    "        loss = F.nll_loss(predict, target)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        if idx % 10 == 0:\n",
    "            print(loss.item())\n",
    "        \n",
    "for i in range(1):\n",
    "    train(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb8a6685",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
